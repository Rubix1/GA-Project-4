{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BeautifulSoup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome(executable_path='./chromedriver/chromedriver.exe')\n",
    "\n",
    "# jobs = ['data-scientist']\n",
    "# # , 'data-analyst', 'business-analyst','research-scientist','machine-learning-engineer'\n",
    "# raw = []\n",
    "# for job in jobs:\n",
    "    \n",
    "#     url = 'https://www.seek.com.au/'+job+'-jobs/'\n",
    "\n",
    "#     driver.get(url)\n",
    "#     WebDriverWait(driver, 3)\n",
    "\n",
    "#     pages = 3\n",
    "    \n",
    "    \n",
    "#     for page in range(2,pages):\n",
    "#         ads = driver.find_elements_by_css_selector('._2iNL7wI')\n",
    "#         links = [ad.get_attribute('href') for ad in ads]\n",
    "#         #print(ads)\n",
    "#         for link in links[2:]:\n",
    "#             driver.get(link)\n",
    "#             WebDriverWait(driver, 3)\n",
    "#             raw_html = driver.page_source\n",
    "#             raw.append([raw_html])\n",
    "#             driver.back()\n",
    "#             WebDriverWait(driver, 3)\n",
    "#         driver.get(url+'?page='+str(page))\n",
    "# raw_df = pd.Series(raw)\n",
    "\n",
    "# driver.close()\n",
    "\n",
    "# raw_df.to_csv('./raw_data.csv',index=False)\n",
    "\n",
    "for i in raw_df:\n",
    "    \n",
    "    ad_list = []\n",
    "    \n",
    "    salarys = []\n",
    "    \n",
    "    soup = BeautifulSoup(i[0],'lxml').text.strip()\n",
    "#     print(type(soup))\n",
    "    salary = re.findall('.*\\$(\\d+).*',soup)\n",
    "    #print(soup.text)\n",
    "#     .findall('.*\\$(\\d+).*')\n",
    "    #break\n",
    "    \n",
    "    #print(salary)\n",
    "    if salary:\n",
    "        \n",
    "        ad_list.append(soup)\n",
    "        \n",
    "        day = re.compile('.*\\d+\\bday')\n",
    "        pa = re.compile('.*\\d+\\bp\\.a\\.|.*\\d+\\bp\\s?a')\n",
    "        hour = re.compile('.*\\d+\\bp[\\.\\s]h.')\n",
    "    \n",
    "        if re.search(day,soup):\n",
    "            \n",
    "            salary = [float(sal)*5*48 for sal in salary if float(sal)>0]\n",
    "            print(salary,str(1))\n",
    "            salarys.append(np.median(salary))\n",
    "            \n",
    "    \n",
    "        elif re.search(pa,soup):\n",
    "            \n",
    "            salary = [float(sal)*1000 for sal in salary if float(sal)>0]\n",
    "            print(salary,str(2))\n",
    "            salarys.append(np.median(salary))\n",
    "\n",
    "        elif re.search(hour,soup):\n",
    "            \n",
    "            salary = [float(sal)*24*5*48 for sal in  salary if float(sal)>0]\n",
    "            print(salary,str(3))\n",
    "            salarys.append(np.median(salary))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            salary = [float(sal) for sal in  salary if float(sal)>0]\n",
    "            print(salary,str(4))\n",
    "            salarys.append(np.median(salary))\n",
    "    \n",
    "    print(salarys)\n",
    "    df_text_salary = pd.DataFrame(zip(ad_list,salarys),columns=['ad_raw','salary'])\n",
    "    print(df_text_salary)\n",
    "    \n",
    "    df_text_salary.to_csv(r'./raw_data.csv',index=False)\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    df_ad_vect_salary = df_text_salary.ad_raw.apply(nlp).apply(lambda x: pd.Series(x.vector))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad_vect_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_mean(x):\n",
    "    if x:\n",
    "        np.mean(np.array(x))\n",
    "        \n",
    "def conditional_regex(input_string):\n",
    "    import re\n",
    "    day = re.compile('day')\n",
    "    pa = re.compile('p\\.a\\.|p\\s?a')\n",
    "    hour = re.compile('p[\\.\\s]h.')\n",
    "\n",
    "    input_string = input_string.lower().replace(',','')\n",
    "    numbers = re.compile('\\$(\\d+)')\n",
    "\n",
    "    if ('day' in input_string)|('daily' in input_string):\n",
    "        return [float(number)*5*48 for number in numbers.findall(input_string) if float(number)>0]\n",
    "    \n",
    "    elif pa.search(input_string.lower()):\n",
    "        return [float(number)*1000 for number in  numbers.findall(input_string) if float(number)>0]\n",
    "\n",
    "    elif hour.search(input_string.lower()):\n",
    "        return [float(number)*24*5*48 for number in  numbers.findall(input_string) if float(number)>0]\n",
    "    elif numbers.search(input_string.lower()):\n",
    "        return [float(number) for number in  numbers.findall(input_string) if float(number)>0]\n",
    "\n",
    "def get_valid_salary(input_string):\n",
    "    \n",
    "    numbers = re.compile('(\\d+)')\n",
    "    \n",
    "    salary = [num for num in numbers.findall(input_string) if(float(num)>0)&(float(num)<999999)]\n",
    "\n",
    "    return salary[0] if salary else None\n",
    "\n",
    "def handle_list(x):\n",
    "    if x:\n",
    "        return np.mean(np.array(x))\n",
    "    else:\n",
    "        return x\n",
    "        \n",
    "import re\n",
    "numbers = re.compile('\\$(\\d+)')\n",
    "new_dfs = []\n",
    "for df in dfs:\n",
    "    new_dfs.append(df)\n",
    "    \n",
    "    if df.filter(regex='salary_data_text').shape[1]>0:\n",
    "        new_dfs[-1]['salary'] = new_dfs[-1]['salary_data_text'].map(lambda x: handle_list(conditional_regex(x)) if isinstance(x,str) else x)\n",
    "    if df.filter(regex='salary_range').shape[1]>0:\n",
    "        new_dfs[-1]['salary'] = new_dfs[-1]['salary_range'].astype(str).map(get_valid_salary)\n",
    "    if pd.api.types.is_object_dtype(df['salary']):\n",
    "        new_dfs[-1]['salary'] = new_dfs[-1]['salary'].astype(str).map(get_valid_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
